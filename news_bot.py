import requests
import os
import re
from datetime import datetime
import time

# 1. ì„¤ì •
TARGET_REPO = "GENEXIS-AI/DailyNews"
FOLDER_PATH = "ë‰´ìŠ¤ë ˆí„°"
API_URL = f"https://api.github.com/repos/{TARGET_REPO}/contents/{FOLDER_PATH}"
WEBHOOK_URL = os.environ.get('SLACK_WEBHOOK_URL')

def send_to_slack():
    res = requests.get(API_URL)
    if res.status_code != 200: return
    files = res.json()
    today_str = datetime.now().strftime("%Y-%m-%d")
    target_file = next((f for f in files if today_str in f['name']), None)
    if not target_file: return

    raw_text = requests.get(target_file['download_url']).text
    
    # ğŸš€ ì‹œì‘ ì•Œë¦¼
    requests.post(WEBHOOK_URL, json={"text": f"ğŸš€ *{today_str} AI ë‰´ìŠ¤ ë°°ë‹¬ ì‹œì‘!*"})
    time.sleep(1)

    # ê¸°ì‚¬ ë¶„ë¦¬ (ê°€ë¡œì¤„ --- ë˜ëŠ” ìƒµ # ê¸°ì¤€)
    sections = re.split(r'\n-{3,}\s*|\n#+\s*', raw_text)

    for section in sections:
        if not section.strip(): continue
        
        # [ìˆ˜ì •] ëª¨ë“  ì´ë¯¸ì§€ íƒœê·¸(![...](...))ë¥¼ í…ìŠ¤íŠ¸ì—ì„œ ì™„ì „íˆ ì œê±°
        clean_text = re.sub(r'!\[.*?\]\(.*?\)', '', section).strip()
        lines = [l.strip() for l in clean_text.split('\n') if l.strip()]
        
        if not lines: continue

        # 1. ì œëª© ì°¾ê¸° ë¡œì§
        clean_title = ""
        content_start_idx = 0
        
        for idx, line in enumerate(lines):
            # 'ì œëª©:', 'ì¤‘ìš”ë„:', 'ì „ì²´ë§í¬:' ë“±ì˜ ë¨¸ë¦¿ë§ê³¼ ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì œê±°
            t = re.sub(r'^\*?\*?ì œëª©\s*:\s*\*?\*?|[#\*\[\]]', '', line).strip()
            
            # 'ì œëª©:' ì´ë¼ëŠ” ê¸€ìë§Œ ìˆëŠ” ì¤„ì€ ë„˜ê¸°ê³ , ì‹¤ì œ ì œëª© í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ì²« ì¤„ì„ ì œëª©ìœ¼ë¡œ ì±„íƒ
            if t and len(t) > 2 and "http" not in t:
                clean_title = t
                content_start_idx = idx + 1
                break
        
        # ê¸°ì‚¬ ì›ë¬¸ ë§í¬ ì°¾ê¸°
        url_match = re.search(r'(https?://[^\s\)\>\]]+)', clean_text)
        
        # ì œëª©ê³¼ ë§í¬ê°€ ì—†ìœ¼ë©´ ê¸°ì‚¬ê°€ ì•„ë‹Œ ê²ƒìœ¼ë¡œ ê°„ì£¼
        if not clean_title or not url_match:
            continue

        url = url_match.group(1).strip()

        # 2. ë³¸ë¬¸ ì¶”ì¶œ (ì œëª© ì´í›„ì˜ ëª¨ë“  ë¬¸ì¥ í¬í•¨, 'ì¤‘ìš”ë„' ë“± ì œì™¸)
        content_lines = []
        for line in lines[content_start_idx:]:
            # ì œì™¸í•  í‚¤ì›Œë“œë“¤
            if any(x in line for x in ["ì¤‘ìš”ë„", "ì „ì²´ë§í¬", "ì „ì²´ ë‰´ìŠ¤ë ˆí„°"]): continue
            # ë§í¬ë§Œ ë©ê·¸ëŸ¬ë‹ˆ ìˆëŠ” ì¤„ì€ ë²„íŠ¼ì´ ëŒ€ì‹ í•˜ë¯€ë¡œ ì œì™¸
            if url
